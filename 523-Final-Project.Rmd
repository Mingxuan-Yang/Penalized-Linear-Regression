---
title: "523 Final Project"
author: "shiny-gold-scraper"
date: "12/13/2019"
output:
  html_document: default
---

```{r setup, include=FALSE}
library(highcharter)
library(dplyr)
library(purrr)
library(stringr)
library(glmnet)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = F}

transformpower <- function(x, power) {
  if (is.na(power)) return (x)
  if (power == 0) return(log(x))
  if (power == Inf) return (exp(x))
  else return (x^power)
}

mutatePower <- function(df, powers) {
  full_power <- sapply(colnames(df), function(x) powers[x])
  transformname <- function(name, power){
    if (is.na(power) || power == 1) return (name)
    if (power == 0) return(paste0("log_", name))
    if (power == Inf) return (paste0("exp_", name))
    else return (paste0(name, "_pwr", power))
  }
  res <- bind_cols(map2(df, full_power, transformpower))
  colnames(res) <- map2(colnames(df), full_power, transformname)
  return (res)
}

reg <- function(df, formula = NULL, response = 1, predictors = -1, interactions = 1,
                model = c("Ridge", "Lasso"), lambda0 = exp(seq(-10, 10, length.out = 300)),
                powerTransform = numeric(0))
{
  ## df:  a data frame with covariates and response
  ## response: the number or the name of response
  ## predictor: the numbers or the names of predictors
  ## interactions: if `formula` is not defined, a positive integer n indicating the level
  ###              of multiway interactions should be included
  ## model: "Ridge" or "Lasso"
  ## lambda0: a sequence of shrinkage parameters to be considered
  
  get_formula <- function(name_y, name_x, power){
    x_str <-paste(name_x, collapse = " + ")
    if (power > 1)
      x_str <- paste0("(", x_str, ") ^ ", power)
    formula_str <- paste(name_y, "~" ,x_str, "- 1")
    return (as.formula(formula_str))
  }
  
  # test validity of parameters
  
  org_Y <- df[, response]
  power_response <- 1 / powerTransform[colnames(df)[response]]
  if (is.na(power_response))
    power_response <- 1
  if (is.character(response))
    response <- which(colnames(df) == response)
  if (is.character(predictors))
    predictors <- which(colnames(df) == predictors)
  df <- df %>% mutatePower(powerTransform)
  # generate formula by interactions
  if (is.null(formula) || formula == ""){
    formula <- get_formula(colnames(df)[response],
                           colnames(df)[predictors],
                           interactions)
  }
  X <- model.matrix(formula, df)
  if ("(Intercept)" %in% colnames(X))
    X <- X[, -1]
  Y <- df[, response]
  X_scaled <- scale(X)
  Y_scaled <- scale(Y)
  
  model <- match.arg(model)
  
  ## Suppose model %in% c("Lasso", "Ridge")
  coef <- do.call(rbind,
    map(lambda0, 
        ~ c(glmnet(X_scaled, Y_scaled, lambda = .x, alpha = ifelse(model == "Lasso", 1, 0)) %>%
            coef() %>% .[-1] %>% set_names(colnames(X_scaled))))
  )
  
  func_predict <- function(newx, lambda, ...){
    tmp <- predict(glmnet(X_scaled, Y_scaled, lambda = lambda, alpha = ifelse(model == "Lasso", 1, 0)),
                   newx = newx, type = "response", ...)
    return (transformpower(
      tmp * attr(Y_scaled, "scaled:scale") + attr(Y_scaled, "scaled:center"),
      power_response
    ))
  }
  
  cv <- cv.glmnet(X_scaled, Y_scaled)
  cv_predict <- function(newx, ...){
    predict(cv, newx, ...)
  }
  
  penalty_func_list <- list(
    "Lasso" = function(x) sum(abs(x), na.rm = T),
    "Ridge" = function(x) sqrt(sum(x^2, na.rm = T))
  )
  penalty_func <- penalty_func_list[[model]]
  
  ols <- lm(Y_scaled ~ X_scaled - 1)
  t <- apply(coef, 1, penalty_func)
  t_ols <- penalty_func(ols$coefficients)
  fitted <- transformpower(
    X_scaled %*% t(coef) * attr(Y_scaled, "scaled:scale") + attr(Y_scaled, "scaled:center"),
    power_response
  )
  fitted_ols <- transformpower(
    ols$fitted.values * attr(Y_scaled, "scaled:scale") + attr(Y_scaled, "scaled:center"),
    power_response
  )
  
  RSS <- apply(fitted, 2, function(x) sum((org_Y - x)^2))
  RSS_ols <- sum((org_Y - fitted_ols) ^ 2)
  
  info <- function(i, j){
    Xs <- as.matrix(X_scaled)[, c(i,j)]
    Xo <- as.matrix(X_scaled)[, -c(i,j)]
    function(lambda){
      coefs <- glmnet(X_scaled, Y_scaled, lambda = lambda, alpha = ifelse(model == "Lasso", 1, 0)) %>%
        coef() %>% .[-1] %>% set_names(colnames(X_scaled))
      bs <- coefs[c(i,j)]
      bo <- coefs[-c(i,j)]
      bc <- solve(t(Xs) %*% (Xs)) %*% t(Xs) %*% (as.matrix(Y_scaled) - Xo %*% bo)
      RSS <- sum((Y_scaled - Xo %*% bo - Xs %*% bs)^2)
      k <- RSS - sum((as.matrix(Y_scaled) - Xo %*% bo - Xs %*% bc)^2)
      eigens <- eigen(t(Xs) %*% Xs, symmetric = T)
      ellipse.res <- list(
        xc = bc[1],
        yc = bc[2],
        a = sqrt(k/eigens$values[2]),
        b = sqrt(k/eigens$values[1]),
        phi = acos(eigens$vectors[1,2] * sign(eigens$vectors[2,2]) / sqrt(sum(eigens$vectors[,2]^2)))
      )
      class(ellipse.res) <- "ellipse"
      t <- penalty_func(bs)
      res <- list(ellipse = ellipse.res, tangent_point = bs, t = t, model = model)
      class(res) <- "regvarinfo"
      return (res)
    }
  }
  
  res <- list(
    formula = formula,
    response = colnames(df)[response],
    predictors = colnames(df)[predictors],
    model = model,
    coef = as.data.frame(coef),
    cv = cv,
    cv.coef = coef(cv),
    ols = ols,
    lambda = lambda0, t = t, t_ols = t_ols,
    X = X, Y = Y,
    X.scale = X_scaled, Y.scale = Y_scaled,
    fun.predict = func_predict,
    cv.predict = cv_predict,
    fitted = fitted, fitted_ols = fitted_ols,
    RSS = RSS, RSS_ols = RSS_ols,
    info = info
  )
  class(res) <- c("reg", "list")
  return (res)
}

print.reg <- function(reg_result, nShow = 5){
  cat("Model Fitted Using", reg_result$model, "\n\n")
  cat("Formula:", paste(reg_result$formula[2], reg_result$formula[3], sep=' ~ '), "\n\n")
  nRow <- nrow(reg_result$coef)
  nSep <- max(floor(nRow / (nShow - 1)) - 1, 1)
  shown <-(0:(nRow - 1)) %% nSep == 0
  cat("OLS regression and", sum(shown), "regression results are\n")
  print(bind_cols(lambda = c(0, reg_result$lambda),
                  rbind(reg_result$ols$coefficients,
                        reg_result$coef))[c(T, shown), ])
  cat("\nCoefficients using cross validation\n")
  cat("lambda: ", reg_result$cv$lambda.1se, "\n")
  res <- reg_result$cv.coef[-1]
  names(res) <- colnames(reg_result$coef)
  print(res)
}

summary.reg <- function(reg_result, nShow = Inf){
  nRow <- nrow(reg_result$coef)
  nSep <- max(floor(nRow / (nShow - 1)) - 1, 1)
  shown <- (0:(nRow - 1)) %% nSep == 0
  cat("OLS regression and", sum(shown), "regression results are\n")
  bind_cols(lambda = c(0,reg_result$lambda),
            param_prop = c(1,reg_result$t / reg_result$t_ols),
            rbind(reg_result$ols$coefficients,
                  reg_result$coef),
            RSS = c(reg_result$RSS_ols, reg_result$RSS))[c(T, shown), ]
}

plot.reg <- function(reg_result, which = 1, x_axis = c("log-lambda", "prop"), plot = T){
  x_axis <- match.arg(x_axis)
  
  ###### function to create an interface
  hc_plot_returns <- function(coef, lambda, prop, name){
    ## coef is the objective data set
    ## name is "Ridge" or "Lasso"
    ## lambda is a sequence of assigned shrinkage parameters, should be positive
    if (x_axis == "log-lambda")
      x_var <- round(log(lambda), 4)
    else if (x_axis == "prop")
      x_var <- round(prop, 4)
    hc_plot <- highchart(type = "chart") %>%
      hc_xAxis(categories = x_var,
               title = list(text = x_axis)) %>%
      hc_yAxis(title = list(text = "coefficient")) %>%
      hc_title(
        text = str_c("Coefficients of <span style=\"color:#e5b13a\"> ", name, "</span> regression"),
        style = list(fontWeight = "bold", useHTML = TRUE),
        align = "center") %>%
      hc_tooltip(borderWidth = 1, table = TRUE, sort = TRUE, 
                 valueDecimals = 4, crosshairs = T)
    
    for(i in 1:ncol(coef)){
      hc_plot <- hc_plot %>%
        hc_add_series(name = colnames(coef)[i], data = coef[,i])
    }
    return(hc_plot)
  }
  if (plot){
    hc_plot_returns_mem <- memoise::memoise(hc_plot_returns)
    hc_plot_returns_mem(reg_result$coef, reg_result$lambda, reg_result$t/reg_result$t_ols, reg_result$model)
  }
  return (hc_plot_returns(reg_result$coef, reg_result$lambda, reg_result$t/reg_result$t_ols, reg_result$model))
}

predict.reg <- function(reg_result, newx, lambda = NULL, log = F, ...){
  if (is.null(lambda)){
    warning("No lambda specified, using cross validation.")
    return (reg_result$cv.predict(newx))
  }
  reg_result$fun.predict(newx, ifelse(log, exp(lambda), lambda), ...)
}

plot.ellipse <- function(ellipse, n = 1, plot = T, ...){
  t <- seq(0, 2*pi, 0.01)
  f <- function(k){
    x <- ellipse$xc + ellipse$a*k/n*cos(t)*cos(ellipse$phi) - ellipse$b*k/n*sin(t)*sin(ellipse$phi)
    y <- ellipse$yc + ellipse$a*k/n*cos(t)*sin(ellipse$phi) + ellipse$b*k/n*sin(t)*cos(ellipse$phi)
    data.frame(k = k, x = x, y = y)
  }
  data <- bind_rows(lapply(1:n, f))
  if (plot){
    print(
      ggplot(data) + 
        geom_point(aes(x = x, y = y, col = factor(k)), show.legend = FALSE, ...) +
        geom_point(data = data.frame(x = ellipse$xc, y = ellipse$yc), aes(x, y))
    )
  }
  return (data)
}

getCircle <- function(radius, npoints = 1000){
  tt <- seq(0, 2*pi, length.out = npoints)
  xx <- radius * cos(tt)
  yy <- radius * sin(tt)
  data <- data.frame(x = xx, y = yy)
  return(data)
}

getSquare <- function(side, npoints = 1000){
  z <- seq(-side, side, length = npoints)
  w <- abs(side - abs(z))
  z <- c(z, z)
  w <- c(w, -w)
  data <- data.frame(x = z, y = w)
  return(data)
}

plot.regvarinfo <- function(info){
  data.ellipse <- plot(info$ellipse, n = 3, plot = F)
  tmp <- info$tangent_point
  data.tp <- data.frame(x = tmp[1], y = tmp[2])
  if (info$model == "Lasso")
    data.restriction <- getSquare(info$t)
  else
    data.restriction <- getCircle(info$t)
  gp <- ggplot() +
    geom_polygon(data = data.restriction, aes(x, y), fill = "#C0C0C0", alpha = 0.5) +
    geom_path(data = data.ellipse, aes(x, y, col = as.factor(k)), show.legend = F) +
    geom_point(aes(x = info$ellipse$xc, y = info$ellipse$yc), size = 2) +
    #geom_text(aes(x = info$ellipse$xc * 0.85, y = info$ellipse$yc * 0.85, label = "beta_OLS")) +
    geom_point(data = data.tp, aes(x,y), size = 2) +
    geom_point(aes(x = 0, y = 0), size = 2, col = "purple") +
    labs(x = "input$x", y = "input$y") +
    coord_fixed() +
    theme_bw(base_size = 15)
  print(gp)
}
```

# Introduction

In this project, we are going to write up a function `reg` which can be converted into a package to help with the process of ridge/lasso regression. Then we might construct, with the help of the function we designed, a shiny app to fit penalized linear regression models, such as Lasso and Ridge, to a dataset uploaded by the user, and more importantly to visualize the process of model fitting.

# Function

```{r, eval = F}
reg <- function(df, formula = NULL, response = 1, predictors = -1, interactions = 1,
                model = c("Ridge", "Lasso"), lambda0 = exp(seq(-10, 10, length.out = 300)),
                powerTransform = numeric(0))
```

## Parameters:

- `df`: a dataframe on which we would build our model on

- `formula`: the regression formula (e.g. `Y ~ X1 + X2 + Z:W`)

- `response`: if `formula` not specified, the column number or name which is used as response

- `predictors`: if `formula` not specified, the column numbers or names which are used as predictors

- `interactions`: if `formula` not specified, to which level of interactions should be included

- `model`: can be **Ridge** or **Lasso**

- `lambda0`: the lambda values of the models

- `powerTransform`: what power transforms should be exerted on the variables.

## Return value

A `reg` object including:

- `formula`: the formula used or generated for fitting the model

- `response`: the name of response column

- `predictors`: the names of predictor columns

- `model`: the specified model (Lasso / Ridge)

- `coef`: a coefficient matrix with each row corresponding to a single lambda value

- `cv`: a `cv.glmnet` object

- `cv.coef`: the coefficients of variables selected using cross validation

- `ols`: the ordinary least square estimation

- `lambda`: the lambda values used for fitting

- `t`: the corresponding restriction parameter to the `lambda`'s

- `t_ols`: the restriction parameter corresponding to the OLS estimation.

- `X`, `Y`: the `X` and `Y` matrix used

- `X.scale`, `Y.scale`: the scaled `X` and `Y` matrix used

- `fun.predict`: a function for prediction

- `cv.predict`: function for prediction using lambda selected by cross validation

- `fitted`: fitted values under each `lambda` value

- `fitted_ols`: fitted values using OLS regression

- `RSS`: residual sum of squares under each `lambda` value

- `RSS_ols`: residual sum of squares under OLS regression

- `info`: information for the equal-RSS ellipses and the restriction area

## Generic Functions

`summary`, `print`, `plot`, `predict`

## Examples 

### Regression using formula

```{r}
swiss <- datasets::swiss
reg1 <- reg(swiss, Fertility ~ Agriculture + Examination + Education, model = "Lasso")
print(reg1, nShow = 5) # nShow by default
```

```{r}
reg2 <- reg(swiss, Fertility ~ Agriculture + (Catholic + Infant.Mortality)^2, model = "Ridge")
summary(reg2)
```

### Regression using predictors and interaction level

```{r}
reg3 <- reg(swiss, model = "Ridge", interaction = 2, lambda0 = exp(seq(-10,0,length.out = 100)),
            powerTransform = c(Education = 2, Catholic = 0))
plot(reg3, x_axis = "log-lambda")
```

```{r}
reg4 <- reg(swiss[6:37, ], formula = Agriculture ~ Education + log(Catholic), model = "Lasso")
predict(reg4, newx = reg4$X[1:5,])
```

### Info under specific lambda

```{r}
reg5 <- reg(swiss, model = "Lasso")
info <- reg5$info(2,3)(0.2) # Select the first and second predictor, and set lambda
plot(info)
```

# Shiny App

Specifically, our app serves the following functions:  
1. Exploratory Data Analysis (EDA), which displays the numeric summary and statistical plots for individual variables from the dataset, together with scatter plots of both type bivariate and trivariate relationships amont different variables.  
2. Regression part, which fits a penalized linear regression model to the uploaded dataset, with a range of parameters to adjust by users, such as model type (Ridge vs. Lasso), shrinkage parameter (well-known as lambda) range and interaction level. Moreover, this part visualizes the process of fitting the model, by displaying how coefficients are shrunk as shrinkage parameter changes and how the final coefficients are settled for a specific choice of lambda.  
3. A series of other fuctions, such as a glossary to offer guidance to users.


Note that the user need to upload a valid data frame object in CSV format in order to navigate into the main page of our shiny app.


## EDA

In this section, the user can obtain the basic summary information of each variable in the provided data set, including minimum value, mean value, maximum value and quantile values. Also, the user can obtain the histogram plot, density plot, bivariate scatter plot and trivariate scatter plot of the variables. This function can help the users to figure out the property of variables and the relationship between them, which will be useful to decide the regression formula later on.

## Regression

In this section, the user can fit the data by specifying a model, or by choosing all the predictors and select the interaction level. The user should be able to see a plot for the coefficients versus the lambda values, as well as detailed table with all the numbers.

## Others

For other parts, see the corresponding instruction in the app.






